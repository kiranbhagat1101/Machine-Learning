{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd#data processing\nimport numpy as np\nimport matplotlib.pyplot as plt#Matplotlib includes the image module for image manipulation\nimport matplotlib.image as mpimg\nimport seaborn as sns#Seaborn provides a high-level interface for drawing attractive and informative statistical graphics.\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools#The itertools module includes a set of functions for working with iterable (sequence-like) data sets.\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential#A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D#1)Dense layer is the regular deeply connected neural network layer.\n#Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly,2)Flattens the input. Does not affect the batch size.\n#Max pooling operation for 2D spatial data.\nfrom keras.optimizers import RMSprop #An optimizer is one of the two arguments required for compiling a Keras model\nfrom keras.preprocessing.image import ImageDataGenerator#Generate batches of tensor image data with real-time data augmentation.\nfrom keras.callbacks import ReduceLROnPlateau#Reduce learning rate when a metric has stopped improving.\n\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# free some space\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  **Check for null and missing values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the data\nX_train.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.isnull().any().describe()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Normalization the data\n"},{"metadata":{},"cell_type":"markdown","source":"\nthe goal of data normalization is to reduce and even eliminate data redundancy,also is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information,\nThe data must be preprocessed before training the network. If you inspect the image , you will see that the pixel values fall in the range of 0 to 255:\n![image.png](attachment:image.png)","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data\nX_train = X_train / 255.0#the CNN converg faster on [0..1] data than on [0..255]\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Reshape"},{"metadata":{},"cell_type":"markdown","source":"The reshape() function is used to give a new shape to an array without changing its data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 28px, width = 28px , chanal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n#Train and test images (28px x 28px) has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some examples\ng = plt.imshow(X_train[1][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label encoding"},{"metadata":{},"cell_type":"markdown","source":"Label Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Labels are 10 digits numbers from 0 to 9.Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split training and valdiation set"},{"metadata":{},"cell_type":"markdown","source":"I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Optimizer ensure the model reaches the optimium faster.**\n\nRMSProp optimizer makes the model converge more effectively and faster. It also stricts the model to coverge at global minimum therefore the accuracy of the model will be higher. \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"learning_rate range between 0.0 and 1.0\n\n"},{"metadata":{},"cell_type":"markdown","source":"By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\nverbose=0 will show you nothing (silent)\nverbose=1 will show you an animated progress bar like this:\n \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3,verbose=1,factor=0.5,min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# when min_lr is =0.05 Epoch 1/2\n439/439 - 151s - loss: 0.4155 - accuracy: 0.8663 - val_loss: 0.0629 - val_accuracy: 0.9829\n# Epoch 2/2\n439/439 - 146s - loss: 0.1300 - accuracy: 0.9615 - val_loss: 0.0609 - val_accuracy: 0.9848"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2# Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 86","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Without data augmentation i obtained an accuracy of 98.114%\n# With data augmentation i achieved 99.67% of accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Without data augmentation i obtained an accuracy of 0.98114\n#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n#          validation_data = (X_val, Y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With data augmentation to prevent overfitting (accuracy 0.99286)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n\n\nprint(datagen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Randomly rotate some training images by 10 degrees\n\nRandomly Zoom by 10% some training images\n\nRandomly shift images horizontally by 10% of the width\n\nRandomly shift images vertically by 10% of the height\n\nI did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.\n\nOnce our model is ready, we fit the training dataset .\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])#CB=Reduce learning rate when a metric has stopped improving.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \n\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='red', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='blue', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='red',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ****Confusion matrix can be very helpfull to see your model drawbacks.\n \n****I plot the confusion matrix of the validation results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(Y_true,Y_pred_classes))#, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's investigate for errors.\n\nI want to see the most important errors . the difference between the probabilities of real value and the predicted ones in the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}